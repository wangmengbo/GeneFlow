{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ae54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 16:06:39,699 - __main__ - INFO - Using device: cuda\n",
      "2025-05-05 16:06:39,700 - __main__ - WARNING - Loading gene expression data from cell_256_aux/normalized.csv\n",
      "2025-05-05 16:06:40,479 - __main__ - INFO - Loaded gene expression data with shape: (87499, 382)\n",
      "2025-05-05 16:06:40,480 - __main__ - INFO - Loading image paths from cell_256_aux/input/cell_image_paths.json\n",
      "2025-05-05 16:06:40,481 - __main__ - INFO - Loaded 1483 cell image paths\n",
      "2025-05-05 16:06:40,482 - __main__ - INFO - Found 1483 existing cell images\n",
      "2025-05-05 16:06:40,528 - dataset - INFO - Dataset contains 21805 valid patches\n",
      "2025-05-05 16:06:40,529 - dataset - INFO - Total number of cells across all patches: 412871\n",
      "2025-05-05 16:06:40,531 - __main__ - INFO - Created DataLoader with 2908 training batches and 727 validation batches\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RNAtoHnEModel.__init__() got an unexpected keyword argument 'input_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 145\u001b[0m\n\u001b[1;32m    142\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_channels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_size\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Image dimensions\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Create the model\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRNAtoHnEModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg_channels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    153\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated model with input dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and output dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Cell 10: Setup Rectified Flow and optimizer\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Setup Rectified Flow\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: RNAtoHnEModel.__init__() got an unexpected keyword argument 'input_dim'"
     ]
    }
   ],
   "source": [
    "# RNA to H&E Cell Image Generator with Rectified Flow\n",
    "# ===================================================\n",
    "\n",
    "# Cell 1: Import libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Cell 2: Import custom modules - adjust the path as needed\n",
    "# If your notebook is in a different location than the original script,\n",
    "# you may need to modify this path\n",
    "notebook_dir = os.path.dirname(os.getcwd())\n",
    "if notebook_dir not in sys.path:\n",
    "    sys.path.append(notebook_dir)\n",
    "\n",
    "# Import our modules - uncomment these after ensuring the modules are available\n",
    "from dataset import CellImageGeneDataset, PatchImageGeneDataset\n",
    "from single_model import RNAtoHnEModel\n",
    "from multi_model import MultiCellRNAtoHnEModel\n",
    "from rectified_flow import RectifiedFlow, EulerSolver\n",
    "from train import train_with_rectified_flow, generate_images_with_rectified_flow\n",
    "from utils import setup_parser, parse_adata, analyze_gene_importance\n",
    "\n",
    "# Cell 3: Set parameters (replacing command-line arguments)\n",
    "# Configuration parameters\n",
    "config = {\n",
    "    'gene_expr': \"cell_256_aux/normalized.csv\",\n",
    "    'image_paths': \"cell_256_aux/input/cell_image_paths.json\",\n",
    "    'patch_image_paths': \"cell_256_aux/input/patch_image_paths.json\",\n",
    "    'patch_cell_mapping': \"cell_256_aux/input/patch_cell_mapping.json\",\n",
    "    'output_dir': 'cell_256_aux/output_rectified',\n",
    "    'epochs': 10,\n",
    "    'batch_size': 6,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'img_size': 256,\n",
    "    'img_channels': 4,\n",
    "    'use_amp': False,\n",
    "    'patience': 5,\n",
    "    'gen_steps': 100,\n",
    "    'seed': np.random.randint(100),\n",
    "    'adata': None  # Set this to your AnnData path if you're using AnnData\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(config['output_dir'], exist_ok=True)\n",
    "\n",
    "# Cell 4: Set device and random seed\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "\n",
    "# Cell 5: Load gene expression data\n",
    "# Load gene expression data\n",
    "missing_gene_symbols = None\n",
    "if config['adata'] is not None:\n",
    "    logger.info(f\"Loading AnnData from {config['adata']}\")\n",
    "    # You'd need to define parse_adata arguments to match the original function\n",
    "    expr_df, missing_gene_symbols = parse_adata(config)\n",
    "else:\n",
    "    logger.warning(f\"Loading gene expression data from {config['gene_expr']}\")\n",
    "    expr_df = pd.read_csv(config['gene_expr'], index_col=0)\n",
    "logger.info(f\"Loaded gene expression data with shape: {expr_df.shape}\")\n",
    "gene_names = expr_df.columns.tolist()\n",
    "\n",
    "# Cell 6: Load image paths\n",
    "logger.info(f\"Loading image paths from {config['image_paths']}\")\n",
    "with open(config['image_paths'], \"r\") as f:\n",
    "    image_paths = json.load(f)\n",
    "logger.info(f\"Loaded {len(image_paths)} cell image paths\")\n",
    "\n",
    "# Filter out non-existent image paths\n",
    "image_paths_tmp = {}\n",
    "for k, v in image_paths.items():\n",
    "    if os.path.exists(v):\n",
    "        image_paths_tmp[k] = v\n",
    "image_paths = image_paths_tmp\n",
    "logger.info(f\"Found {len(image_paths)} existing cell images\")\n",
    "\n",
    "# Cell 7: Create dataset\n",
    "# Load patch_to_cells mapping if needed\n",
    "with open(config['patch_cell_mapping'], \"r\") as f:\n",
    "    patch_cell_mappings = json.load(f)\n",
    "\n",
    "# Load patch image paths if needed\n",
    "with open(config['patch_image_paths'], \"r\") as f:\n",
    "    patch_image_paths = json.load(f)\n",
    "\n",
    "# Create PatchImageGeneDataset\n",
    "dataset = PatchImageGeneDataset(\n",
    "    expr_df=expr_df,\n",
    "    patch_image_paths=patch_image_paths,  # Simple dict mapping cell_id -> image_path\n",
    "    patch_to_cells=patch_cell_mappings,  # Dict mapping patch_id -> image_path\n",
    "    img_size=config['img_size'],\n",
    ")\n",
    "\n",
    "# Cell 8: Create DataLoader\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    ")\n",
    "\n",
    "logger.info(f\"Created DataLoader with {len(train_loader)} training batches and {len(val_loader)} validation batches\")\n",
    "\n",
    "# Cell 9: Define model\n",
    "# Define input and output dimensions\n",
    "input_dim = len(gene_names)  # Number of genes\n",
    "output_dim = config['img_channels'] * config['img_size'] * config['img_size']  # Image dimensions\n",
    "\n",
    "# Create the model\n",
    "model = MultiCellRNAtoHnEModel(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    hidden_dims=[512, 256, 128],\n",
    "    img_channels=config['img_channels'],\n",
    "    img_size=config['img_size'],\n",
    ").to(device)\n",
    "\n",
    "logger.info(f\"Created model with input dimension {input_dim} and output dimension {output_dim}\")\n",
    "\n",
    "# Cell 10: Setup Rectified Flow and optimizer\n",
    "# Setup Rectified Flow\n",
    "flow = RectifiedFlow(model=model)\n",
    "solver = EulerSolver(flow=flow, steps=config['gen_steps'])\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['lr'],\n",
    "    weight_decay=config['weight_decay'],\n",
    ")\n",
    "\n",
    "# Cell 11: Train the model\n",
    "# Train the model with rectified flow\n",
    "train_losses, val_losses = train_with_rectified_flow(\n",
    "    flow=flow,\n",
    "    solver=solver,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    epochs=config['epochs'],\n",
    "    output_dir=config['output_dir'],\n",
    "    patience=config['patience'],\n",
    "    use_amp=config['use_amp'],\n",
    ")\n",
    "\n",
    "# Cell 12: Plot training and validation losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.savefig(os.path.join(config['output_dir'], 'loss_curve.png'))\n",
    "plt.show()\n",
    "\n",
    "# Cell 13: Generate images with trained model\n",
    "# Select a few samples for generation\n",
    "num_samples = 5\n",
    "sample_indices = np.random.choice(len(val_dataset), num_samples, replace=False)\n",
    "sample_data = [val_dataset[i] for i in sample_indices]\n",
    "\n",
    "# Generate images\n",
    "generated_images = generate_images_with_rectified_flow(\n",
    "    flow=flow,\n",
    "    solver=solver,\n",
    "    samples=sample_data,\n",
    "    device=device,\n",
    "    img_size=config['img_size'],\n",
    "    img_channels=config['img_channels'],\n",
    ")\n",
    "\n",
    "# Cell 14: Visualize generated images\n",
    "fig, axes = plt.subplots(num_samples, 2, figsize=(10, 3 * num_samples))\n",
    "\n",
    "for i, (sample, gen_img) in enumerate(zip(sample_data, generated_images)):\n",
    "    # Original image\n",
    "    if config['img_channels'] == 3:\n",
    "        axes[i, 0].imshow(sample['image'].permute(1, 2, 0).cpu().numpy())\n",
    "    else:\n",
    "        axes[i, 0].imshow(sample['image'][0].cpu().numpy(), cmap='gray')\n",
    "    axes[i, 0].set_title(f\"Original Image {i+1}\")\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Generated image\n",
    "    if config['img_channels'] == 3:\n",
    "        axes[i, 1].imshow(gen_img.permute(1, 2, 0).cpu().numpy())\n",
    "    else:\n",
    "        axes[i, 1].imshow(gen_img[0].cpu().numpy(), cmap='gray')\n",
    "    axes[i, 1].set_title(f\"Generated Image {i+1}\")\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config['output_dir'], 'sample_generated_images.png'))\n",
    "plt.show()\n",
    "\n",
    "# Cell 15: Analyze gene importance\n",
    "# Analyze which genes are most important for image generation\n",
    "importance_scores = analyze_gene_importance(model, gene_names, device)\n",
    "\n",
    "# Plot top 20 most important genes\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_indices = np.argsort(importance_scores)[-20:]\n",
    "plt.barh(np.array(gene_names)[top_indices], importance_scores[top_indices])\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Gene Name')\n",
    "plt.title('Top 20 Most Important Genes for Image Generation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config['output_dir'], 'gene_importance.png'))\n",
    "plt.show()\n",
    "\n",
    "# Cell 16: Save the model\n",
    "# Save the trained model\n",
    "model_save_path = os.path.join(config['output_dir'], 'rna_to_image_model.pt')\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'config': config,\n",
    "    'gene_names': gene_names,\n",
    "}, model_save_path)\n",
    "\n",
    "logger.info(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9797d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
